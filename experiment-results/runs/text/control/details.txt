In order to test the hypothesis that taking advantage of modern LLMs' ability to handle larger input tokens with relatively little 